
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Rust NB!">
      
      
        <meta name="author" content="Eurekaimer">
      
      
        <link rel="canonical" href="https://www.eurekaimer.xyz/Stathelper/%E7%BB%9F%E8%AE%A1%E5%AD%A6/%E8%BF%90%E7%AD%B9%E4%B8%8E%E4%BC%98%E5%8C%96/%E6%97%A0%E7%BA%A6%E6%9D%9F%E9%97%AE%E9%A2%98/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../../images/xiaoju.jpg">
      <meta name="generator" content="zensical-0.0.19">
    
    
      
        <title>无约束问题 - Eurekaimer's Digital Garden</title>
      
    
    
      
        
      
      <link rel="stylesheet" href="../../../assets/stylesheets/modern/main.d4922b3c.min.css">
      
        
          
        
        <link rel="stylesheet" href="../../../assets/stylesheets/modern/palette.dfe2e883.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=LXGW+WenKai:300,300i,400,400i,500,500i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"LXGW WenKai";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../../stylesheets/anime-grid.css">
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,t)=>(e<<5)-e+t.charCodeAt(0)),0),__md_get=(e,t=localStorage,a=__md_scope)=>JSON.parse(t.getItem(a.pathname+"."+e)),__md_set=(e,t,a=localStorage,_=__md_scope)=>{try{a.setItem(_.pathname+"."+e,JSON.stringify(t))}catch(e){}},document.documentElement.setAttribute("data-platform",navigator.platform)</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="Eurekaimer&#x27;s Digital Garden" class="md-header__button md-logo" aria-label="Eurekaimer's Digital Garden" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="lucide lucide-pi" viewBox="0 0 24 24"><path d="M9 4v16M4 7c0-1.7 1.3-3 3-3h13"/><path d="M18 20c-1.7 0-3-1.3-3-3V4"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="lucide lucide-menu" viewBox="0 0 24 24"><path d="M4 5h16M4 12h16M4 19h16"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Eurekaimer's Digital Garden
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              无约束问题
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="lucide lucide-sun-moon" viewBox="0 0 24 24"><path d="M12 2v2M14.837 16.385a6 6 0 1 1-7.223-7.222c.624-.147.97.66.715 1.248a4 4 0 0 0 5.26 5.259c.589-.255 1.396.09 1.248.715M16 12a4 4 0 0 0-4-4M19 5l-1.256 1.256M20 12h2"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="lucide lucide-sun" viewBox="0 0 24 24"><circle cx="12" cy="12" r="4"/><path d="M12 2v2M12 20v2M4.93 4.93l1.41 1.41M17.66 17.66l1.41 1.41M2 12h2M20 12h2M6.34 17.66l-1.41 1.41M19.07 4.93l-1.41 1.41"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="lucide lucide-moon" viewBox="0 0 24 24"><path d="M20.985 12.486a9 9 0 1 1-9.473-9.472c.405-.022.617.46.402.803a6 6 0 0 0 8.268 8.268c.344-.215.825-.004.803.401"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="lucide lucide-search" viewBox="0 0 24 24"><path d="m21 21-4.34-4.34"/><circle cx="11" cy="11" r="8"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog" aria-label="查找">
  <button type="button" class="md-search__button">
    查找
  </button>
</div>
      
    
    <div class="md-header__source">
      
        <a href="https://github.com/Eurekaimer/Stathelper" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      
    </div>
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  Stathelper

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../HDP/" class="md-tabs__link">
          
  
  HDP

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../STAT260/" class="md-tabs__link">
          
  
  STAT260

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../CS61A/" class="md-tabs__link">
          
  
  CS61A

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Analysis/" class="md-tabs__link">
          
  
  Analysis

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../ACG/Yuri/" class="md-tabs__link">
          
  
  ACG

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../WebSource/" class="md-tabs__link">
          
  
  Web Source

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../friends-link/" class="md-tabs__link">
        
  
  Friends Link

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Eurekaimer&#x27;s Digital Garden" class="md-nav__button md-logo" aria-label="Eurekaimer's Digital Garden" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="lucide lucide-pi" viewBox="0 0 24 24"><path d="M9 4v16M4 7c0-1.7 1.3-3 3-3h13"/><path d="M18 20c-1.7 0-3-1.3-3-3V4"/></svg>

    </a>
    Eurekaimer's Digital Garden
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Eurekaimer/Stathelper" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Stathelper
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../HDP/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    Index
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../STAT260/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    STAT260 2021
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../CS61A/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    CS61A
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../Analysis/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    分析学总站
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../ACG/Yuri/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    ACG
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../WebSource/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    TBA
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../friends-link/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Friends Link
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        基本概念
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="基本概念">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        极值问题
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convex-planning" class="md-nav__link">
    <span class="md-ellipsis">
      
        凸规划(convex planning)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        下降迭代算法
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        一维搜索
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="一维搜索">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fibonacci" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fibonacci法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#0618" class="md-nav__link">
    <span class="md-ellipsis">
      
        0.618法(黄金分割法)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        牛顿法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        割线法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        抛物线法
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alpha_k" class="md-nav__link">
    <span class="md-ellipsis">
      
        \(\alpha_{k}\)的选取
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="\(\alpha_{k}\)的选取">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        精确线搜索算法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        非精确线搜索算法
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      
        无约束极值问题的解法
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="无约束极值问题的解法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      
        梯度法(最速下降法)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="梯度法(最速下降法)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    <span class="md-ellipsis">
      
        梯度法的基本原理
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      
        计算步骤
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    <span class="md-ellipsis">
      
        最速下降法算法
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conjugate-gradient-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        共轭梯度法(Conjugate gradient method)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="共轭梯度法(Conjugate gradient method)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    <span class="md-ellipsis">
      
        共轭方向
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    <span class="md-ellipsis">
      
        正定二次函数的共轭梯度法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    <span class="md-ellipsis">
      
        计算步骤
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    <span class="md-ellipsis">
      
        非二次函数的共轭梯度法
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_20" class="md-nav__link">
    <span class="md-ellipsis">
      
        牛顿法与拟牛顿法
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="牛顿法与拟牛顿法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_21" class="md-nav__link">
    <span class="md-ellipsis">
      
        牛顿法原理
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_22" class="md-nav__link">
    <span class="md-ellipsis">
      
        构造近似矩阵
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smwsherman-morrison-woodbury-formula" class="md-nav__link">
    <span class="md-ellipsis">
      
        SMW(Sherman-Morrison-Woodbury) Formula
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bfgs" class="md-nav__link">
    <span class="md-ellipsis">
      
        BFGS方法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_23" class="md-nav__link">
    <span class="md-ellipsis">
      
        不变性和二次终止性
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
                



  


              
              <article class="md-content__inner md-typeset">
                
                  
  
    <a href="https://github.com/Eurekaimer/Stathelper/edit/master/docs/统计学/运筹与优化/无约束问题.md" title="编辑此页" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="lucide lucide-file-pen" viewBox="0 0 24 24"><path d="M12.659 22H18a2 2 0 0 0 2-2V8a2.4 2.4 0 0 0-.706-1.706l-3.588-3.588A2.4 2.4 0 0 0 14 2H6a2 2 0 0 0-2 2v9.34"/><path d="M14 2v5a1 1 0 0 0 1 1h5M10.378 12.622a1 1 0 0 1 3 3.003L8.36 20.637a2 2 0 0 1-.854.506l-2.867.837a.5.5 0 0 1-.62-.62l.836-2.869a2 2 0 0 1 .506-.853z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/Eurekaimer/Stathelper/raw/master/docs/统计学/运筹与优化/无约束问题.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="lucide lucide-file-code-2" viewBox="0 0 24 24"><path d="M4 12.15V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.706.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2h-3.35"/><path d="M14 2v5a1 1 0 0 0 1 1h5M5 16l-3 3 3 3M9 22l3-3-3-3"/></svg>
    </a>
  


<h1 id="_1">无约束问题</h1>
<table>
<thead>
<tr>
<th>内容</th>
<th>重要性</th>
<th>描述和注</th>
</tr>
</thead>
<tbody>
<tr>
<td>凸规划概念以及性质</td>
<td>⭐⭐⭐</td>
<td>主要掌握局部极值为全局极值</td>
</tr>
<tr>
<td>Fibonacci法和0.618法</td>
<td>⭐⭐⭐⭐</td>
<td>只需要掌握算法步骤应该就可以了</td>
</tr>
<tr>
<td>一维搜索</td>
<td>⭐⭐⭐⭐</td>
<td>Armijo准则和Zoutendijk定理</td>
</tr>
<tr>
<td>最速下降法</td>
<td>⭐⭐⭐⭐⭐</td>
<td>相当重要的算法，机器学习的灵魂</td>
</tr>
<tr>
<td>共轭梯度法</td>
<td>⭐⭐⭐⭐⭐</td>
<td>思路很巧妙，除算法外还可以思考证明</td>
</tr>
<tr>
<td>拟牛顿法</td>
<td>⭐⭐⭐⭐⭐</td>
<td>掌握DFP,BFGS方法即可</td>
</tr>
</tbody>
</table>
<h2 id="_2">基本概念</h2>
<p><strong>非线性规划</strong>问题的数学模型(同理线性规划，只是函数不再要求线性)</p>
<h3 id="_3">极值问题</h3>
<ol>
<li>局部极值和全局极值</li>
<li>极值点存在的条件<ol>
<li><strong>必要条件：梯度为0</strong></li>
<li>充分条件：梯度为0且Hesse矩阵是半正定(半负定)</li>
</ol>
</li>
<li>凸函数和凹函数(定义和性质)<ol>
<li>凸函数的性质</li>
<li>函数凸性的判定</li>
</ol>
</li>
<li>凸函数的极值(极小值就是最小值)<ol>
<li>凸函数的任一极小点就是它在<span class="arithmatex">\(R\)</span>上的最小点，而且极小点集为凸集</li>
<li>可微的凸函数，如果<span class="arithmatex">\(\exists X^{*}\in R,\forall X\in R,\nabla f(X^{*})^{T}(X-X^{*})\geqslant 0\)</span>，则<span class="arithmatex">\(X^{*}\)</span>是<span class="arithmatex">\(f(X)\)</span>在<span class="arithmatex">\(R\)</span>上的最小点</li>
</ol>
</li>
</ol>
<p>对于第三点中的性质与判定总结如下：</p>
<blockquote>
<p>[!NOTE] 凸函数简单性质
1. <span class="arithmatex">\(f(x)\)</span>为定义在凸集<span class="arithmatex">\(R\)</span>上的凸函数，则对于任意<span class="arithmatex">\(\beta\in R&gt;0\)</span>，函数<span class="arithmatex">\(\beta f(x)\)</span>也是定义在<span class="arithmatex">\(R\)</span>上的凸函数
2. <span class="arithmatex">\(f_{1},f_{2}\)</span>为定义在凸集<span class="arithmatex">\(R\)</span>上的凸函数，则<span class="arithmatex">\(f=f_{1}+f_{2}\)</span>也是定义在<span class="arithmatex">\(R\)</span>上的凸函数
3. <span class="arithmatex">\(f(x)\)</span>为定义在凸集<span class="arithmatex">\(R\)</span>上的凸函数，则对于任意<span class="arithmatex">\(\beta\in R\)</span>，集合<span class="arithmatex">\(S_{\beta}\left\{ X|X\in R,f(X)\leqslant \beta \right\}\)</span>是凸集(<span class="arithmatex">\(S_{\beta}\)</span>称为水平集)</p>
<p>[!NOTE] 函数凸性的判定
显然可以利用定义直接判定，对于可微的凸函数也可以使用下面两个判定定理
1. 一阶条件 <span class="arithmatex">\(R\)</span>为<span class="arithmatex">\(E^{n}\)</span>上开凸集，<span class="arithmatex">\(f(X)\)</span>在<span class="arithmatex">\(R\)</span>上具有一阶连续偏导数，则<span class="arithmatex">\(f(X)\)</span>为<span class="arithmatex">\(R\)</span>上凸函数的充要条件是对任意<span class="arithmatex">\(X^{(1)},X^{(2)}\in R\)</span>，恒有<span class="arithmatex">\(f(X^{(2)})\geqslant f(X^{(1)})+\nabla f(X^{(1)})^{T}(X^{(2)}-X^{(1)})\)</span>
2. 二阶条件 <span class="arithmatex">\(R\)</span>为<span class="arithmatex">\(E^{n}\)</span>上开凸集，<span class="arithmatex">\(f(X)\)</span>在<span class="arithmatex">\(R\)</span>上具有二阶连续偏导数，则<span class="arithmatex">\(f(X)\)</span>为<span class="arithmatex">\(R\)</span>上凸函数的充要条件是<span class="arithmatex">\(f(X)\)</span>的Hessian矩阵<span class="arithmatex">\(H(X)\)</span>在<span class="arithmatex">\(R\)</span>上处处半正定</p>
</blockquote>
<p>凸函数的定义实际上是说凸函数两点间的线性插值不低于这个函数的值，而判定定理1则是说，基于某个点导数的线性近似不高于这个函数的值(几何意义的理解方式)</p>
<p>可以证明<strong>若凸规划的可行域是凸集，局部最优解也是全局最优解，而且最优解的集合形成一个凸集</strong>，那么凸规划的目标函数为严格凸函数时，其最优解必定唯一(这一找到局部最优也就是全局最优)</p>
<blockquote>
<p>[!NOTE] Theorem
若<span class="arithmatex">\(f(X)\)</span>是定义在凸集上的可微凸函数，若存在<span class="arithmatex">\(X^{*}\in R\)</span>，使得对于所有的<span class="arithmatex">\(X\in R\)</span>有<span class="arithmatex">\(\nabla f(X^{*})(X-X^{*})\geqslant 0\)</span>，则<span class="arithmatex">\(X^{*}\)</span>为<span class="arithmatex">\(f(X)\)</span>在<span class="arithmatex">\(R\)</span>上的最小点(全局极小值)</p>
</blockquote>
<h3 id="convex-planning">凸规划(convex planning)</h3>
<blockquote>
<p>[!important] Claim
凸的就是好的！</p>
</blockquote>
<p>凸规划是一类简单而又有重要意义的非线性规划(线性规划也是凸规划)</p>
<h3 id="_4">下降迭代算法</h3>
<p>为了求某可微函数的最优解可以先使该函数的梯度为0，<strong>求得平稳点</strong>然后利用充分条件进行判定，对于简单函数这种方法是可行的，对于比较复杂的函数则不容易求解非线性方程组，可以直接使用迭代法.</p>
<p>迭代法的基本思想是<strong>按照某种规划或算法找出比原解更好的解</strong>，得到一个序列然后用<strong>柯西收敛准则</strong>进行判定，由于计算机只能有限迭代所以达到一定精度后即可停止(注意算法需要给出一个初始估计值<span class="arithmatex">\(X^{(0)}\)</span>).</p>
<blockquote>
<p>[!example] 一些基本定义
搜索方向：能够沿该方向使目标函数值有所下降
步长(步长因子)：沿着搜索方向移动的距离</p>
</blockquote>
<p>下降迭代算法的步骤：</p>
<ol>
<li>选定初始点</li>
<li>确定<strong>搜索方向</strong>(最关键的一步)</li>
<li>从初始点出发沿方向求步长产生下一个迭代点</li>
<li>检查得到的新点是否为极小点或近似极小点</li>
</ol>
<p>注：各种算法的区分，主要是在于确定搜索方向的方法不同</p>
<p>确定步长的方法：</p>
<ul>
<li><strong>常数方法</strong>：定义为常数，无法保证目标函数值下降</li>
<li><strong>可接受点算法</strong>：只要能使目标函数下降就可以任意选取步长</li>
<li>基于沿搜索方向使目标函数值下降<strong>最多</strong>，这一过程称为<strong>一维搜索</strong>或<strong>线搜索</strong>，确定的步长为<strong>最佳步长</strong></li>
</ul>
<p>一维搜索的一个<strong>重要的性质</strong>就是：在搜索方向上所得<strong>最优点</strong>处的梯度和该搜索方向<strong>正交</strong>，归纳为下面的定理</p>
<blockquote>
<p>[!tip] Theorem 7
设<span class="arithmatex">\(f(X)\)</span>有一阶连续偏导数，<span class="arithmatex">\(X^{(k+1)}\)</span>按下列规则迭代：
<span class="arithmatex">\(\lambda_{k}:\min f(X^{(k)}+\lambda P^{(k)}),X^{(k+1)}=X^{(k)}+\lambda_{k}P^{(k)}\)</span>
则有<span class="arithmatex">\(\nabla f(X^{(k+1)})^{T}P^{(k)}=0\)</span></p>
</blockquote>
<p><code>Proof.</code></p>
<p>简单证明一下，构造函数<span class="arithmatex">\(\phi(\lambda)=f(X^{(k)}+\lambda P^{(k)})\)</span>，那么有<span class="arithmatex">\(\phi'(\lambda_{k})=0\)</span>(一阶条件)，代入函数为<span class="arithmatex">\(\nabla f(X^{(k)}+\lambda_{k}P^{(k)})^{T}P^{(k)}=\nabla f(X^{(k+1)})^{T}P^{(k)}=0\)</span></p>
<p>下面讨论算法的收敛速度</p>
<p>若是序列<span class="arithmatex">\(\left\{ X^{(k)} \right\}\)</span>收敛于<span class="arithmatex">\(X^{*}\)</span>，存在与迭代次数无关的数<span class="arithmatex">\(0&lt;\beta&lt;\infty\)</span>和<span class="arithmatex">\(\alpha \geqslant 1\)</span>，使得K从某个<span class="arithmatex">\(k_{0}&gt;0\)</span>开始，都有</p>
<div class="arithmatex">\[
\lVert X^{(k+1)}-X^{*} \rVert \leqslant \beta \lVert X^{(k)}-X^{*} \rVert ^{\alpha}
\]</div>
<p>就称<span class="arithmatex">\(\left\{ X^{(k)} \right\}\)</span>收敛的阶为<span class="arithmatex">\(\alpha\)</span>，或是<span class="arithmatex">\(\alpha\)</span>阶收敛</p>
<ul>
<li><span class="arithmatex">\(\alpha=2\)</span>称为二阶收敛，也可说具有二阶敛速</li>
<li><span class="arithmatex">\(\alpha&gt;1\)</span>称为超线性收敛</li>
<li><span class="arithmatex">\(\alpha=1\)</span>，且<span class="arithmatex">\(0&lt;\beta&lt;1\)</span>称线性收敛或一阶收敛</li>
<li><span class="arithmatex">\(\alpha=1,\beta=1\)</span>称为次线性收敛</li>
</ul>
<p>注：就是一些概念而已，类似Lipschitz条件</p>
<p>还需要决定什么时候停止计算</p>
<p>常用的终止计算准则(<span class="arithmatex">\(\varepsilon_{i}\)</span>为事先给定的足够小的正数)：</p>
<ol>
<li>根据相继两次迭代的绝对误差：<span class="arithmatex">\(\lvert X^{(k+1)}-X^{(k)} \rvert&lt;\varepsilon_{1}\)</span></li>
<li>根据相继两次迭代的相对误差：<span class="arithmatex">\(\frac{\lvert X^{(k+1)}-X^{(k)} \rvert}{\lvert X^{(k)} \rvert}&lt; \varepsilon_{3}\)</span>，这时要求分母不接近于0</li>
<li>根据目标函数梯度的模足够小：<span class="arithmatex">\(\lvert \nabla f(X^{(k)}) \rvert&lt;\varepsilon_{5}\)</span></li>
</ol>
<h2 id="_5">一维搜索</h2>
<p>常用的一维搜索方法</p>
<ul>
<li>试探法("斐波那契法"，0.618法)</li>
<li>插值法(抛物线插值法，三次插值法)</li>
<li>微积分中的求根法(切线法，二分法)</li>
</ul>
<p>注：以下的两种方法Fibonacci法和0.618法都需要在单峰函数的条件下使用否则可能会收敛到错误的位置(错误收敛).</p>
<p>补充单峰函数的定义(这在图形上是显然的)：</p>
<blockquote>
<p>[!NOTE] 单峰函数
<span class="arithmatex">\(f\)</span>是定义在<span class="arithmatex">\(\left[ a,b \right]\)</span>上的一元实函数，<span class="arithmatex">\(\overline{x}\)</span>是<span class="arithmatex">\(f\)</span>在<span class="arithmatex">\(\left[ a,b \right]\)</span>上的极小点，并且对任意的<span class="arithmatex">\(x^{(1)},x^{(2)}\in \left[ a,b \right],x^{(1)}&lt;x^{(2)}\)</span>，有<span class="arithmatex">\(x^{(2)}\leqslant \overline{x},f(x^{(1)})&gt;f(x^{(2)})\)</span>,<span class="arithmatex">\(x^{(1)}\geqslant \overline{x},f(x^{(1)})&lt;f(x^{(2)})\)</span></p>
</blockquote>
<h3 id="fibonacci">Fibonacci法</h3>
<p>算法原理(考虑单峰函数)：</p>
<ul>
<li>内部取两个点划分区间</li>
<li>判断两点函数值大小重新确认区间</li>
<li>继续搜索</li>
</ul>
<p>实际就是通过不断缩短区间长度达到即使在区间内反复摆动也可以达到比较好的近似极值点的效果</p>
<blockquote>
<p>[!question] 缩短率与计算次数的关系
计算函数值<span class="arithmatex">\(n\)</span>次，能把包含极小点的区间缩小到什么程度?计算<span class="arithmatex">\(n\)</span>次可以把原本多大的区间缩小为一个单位长度的区间.</p>
</blockquote>
<p>这种方法迭代n次的缩短率符合Fibonacci数列的值记第n次迭代值为<span class="arithmatex">\(F_{n}\)</span></p>
<p>那么如果要使迭代n次后的长度缩短为原本长度的<span class="arithmatex">\(\delta\)</span>倍(中文上语病忽略)，只需要保证<span class="arithmatex">\(F_{n}\geqslant \frac{1}{\delta}\)</span></p>
<p>缩短区间的步骤：</p>
<ol>
<li>确定试点的个数<span class="arithmatex">\(n\)</span>，简单根据Fabonacci数列的值即可得到</li>
<li>选取前两个试点的位置</li>
<li><span class="arithmatex">\(t_{1}=a_{0}+ \frac{F_{n-2}}{F_{n}}(b_{1}-a_{1})=b_{0}+\frac{F_{n-1}}{F_{n}}(a_{0}-b_{0})\)</span></li>
<li><span class="arithmatex">\(t_{1}'=a_{0}+ \frac{F_{n-1}}{F_{n}}(b_{0}-a_{0})\)</span></li>
<li>计算两个函数值比较大小</li>
<li>计算新的点函数值然后迭代 </li>
</ol>
<p>可以画一个简单的图表示点的复用关系</p>
<p><img alt="Fibonacci" src="https://cdn.jsdelivr.net/gh/Eurekaimer/MyIMGs@main/img/Fibonacci-graph" /></p>
<h3 id="0618">0.618法(黄金分割法)</h3>
<p>实际上就是Fibonacci方法的比值求极限得到黄金分割比，然后利用<strong>黄金分割点的内生性</strong>就可以增加选取点和分割区间的效率(<strong>数学文化</strong>的含金量还在上升)</p>
<p>不管是黄金分割法还是Fibonacci法，选取的点基本都被复用过，这样就提高了效率减少了成本：不要浪费！</p>
<p>其他的一些方法：</p>
<ul>
<li>二分法</li>
<li>牛顿法<ul>
<li>在极小点附近用二阶泰勒展开逼近得到估计</li>
<li>一直利用切线迭代即可</li>
</ul>
</li>
<li>割线法</li>
<li>抛物线法</li>
<li>两点三次插值法</li>
</ul>
<blockquote>
<p>[!tip] 信息和算法
已知信息的多少会决定算法的复杂度和算法效率，所以笔者想到了一些优化方向：
+ 少信息如何达到基本的精度和效率？
+ 多信息怎么达到最高的效率？</p>
</blockquote>
<h3 id="_6">牛顿法</h3>
<p>基本思想：在极小点附近用二阶Talor多项式近似目标函数<span class="arithmatex">\(f(x)\)</span>，进而求出极小点的估计值</p>
<div class="arithmatex">\[
\min f(X)\ x\in \mathbb{R}^{1}
\]</div>
<p>令</p>
<div class="arithmatex">\[
\phi(x)=f(x^{(k)})+f'(x^{(k)})(x-x^{(k)})+ \frac{1}{2}f''(x^{(k)})(x-x^{(k)})^{2}
\]</div>
<p>求导得</p>
<div class="arithmatex">\[
\begin{aligned}
\phi'(x)&amp;=f'(x^{(k)})+f''(x^{(k)})(x-x^{(k)})=0\\
x^{(k+1)}&amp;=x^{(k)}- \frac{f'(x^{(k)})}{f''(x^{(k)})}
\end{aligned}
\]</div>
<blockquote>
<p>[!NOTE] 牛顿法(算法步骤)
(1) 给定初点<span class="arithmatex">\(x^{(0)}\)</span>，允许误差<span class="arithmatex">\(\varepsilon&gt;0,k=0\)</span>
(2) 若<span class="arithmatex">\(\lvert f'(x^{(k)}) \rvert&lt;\varepsilon\)</span>，则停止迭代，得到<span class="arithmatex">\(x^{(k)}\)</span>
(3) 计算点<span class="arithmatex">\(x^{(k+1)}\)</span></p>
<div class="arithmatex">\[x^{(k+1)}=x^{(k)}- \frac{f'(x^{(k)})}{f''(x^{(k)})},k=k+1 \]</div>
<p>牛顿法的收敛速度和收敛性受初始点选择的影响较大，如果初始点选择的很接近目标函数极小值点那么收敛的会很快，反之不一定收敛</p>
</blockquote>
<h3 id="_7">割线法</h3>
<div class="arithmatex">\[
\phi(x)=f'(x^{(k)})+ \frac{f'(x^{(k)})-f'(x^{(k-1)})}{x^{(k)}-x^{(k-1)}}(x-x^{(k)})=0
\]</div>
<p>如图所示：</p>
<p><img alt="割线法" src="https://cdn.jsdelivr.net/gh/Eurekaimer/MyIMGs@main/img/%E5%89%B2%E7%BA%BF%E6%B3%95.png" /></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">secant_method</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">iterations</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return the root calculated using the secant method.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="n">x0</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x0</span><span class="p">))</span>
        <span class="n">x0</span><span class="p">,</span> <span class="n">x1</span> <span class="o">=</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span>
        <span class="c1"># Apply a stopping criterion here (see below)</span>
    <span class="k">return</span> <span class="n">x2</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f_example</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">612</span>

<span class="n">root</span> <span class="o">=</span> <span class="n">secant_method</span><span class="p">(</span><span class="n">f_example</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Root: </span><span class="si">{</span><span class="n">root</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Root: 24.738633748750722</span>
</code></pre></div>
<p>相比于牛顿法来说收敛速度比较慢，但是不需要计算二阶导数，缺点就是和牛顿法一样也不具有全局收敛性，如果初始点选择的不好可能不收敛</p>
<h3 id="_8">抛物线法</h3>
<p>基本思想是在极小点附近用二次三项式<span class="arithmatex">\(\phi(x)\)</span>逼近目标函数<span class="arithmatex">\(f(x)\)</span>，令<span class="arithmatex">\(\phi(x),f(x)\)</span>在三个点处具有相同的函数值并且还具有以下关系：</p>
<div class="arithmatex">\[
f(x^{1})&gt;f(x^{2}),f(x^{2})&lt;f(x^{3});x^{1}&lt;x^{2}&lt;x^{3}
\]</div>
<p>那么为了求<span class="arithmatex">\(\phi(x)\)</span>的极小点，令<span class="arithmatex">\(\phi'(x)=b+2cx=0,x= - \frac{b}{2c}\)</span></p>
<p>插值法的原理比较多，也比较复杂但是并不是很难可以自己参考资料(可以参考JLU的一本数值分析初步)</p>
<p>以下是补充的内容，考试不做要求</p>
<h2 id="alpha_k"><span class="arithmatex">\(\alpha_{k}\)</span>的选取</h2>
<h3 id="_9">精确线搜索算法</h3>
<p>首先构造一元辅助函数(<span class="arithmatex">\(d^{k}\)</span>是给定的下降方向)</p>
<div class="arithmatex">\[
\phi(\alpha)=f(x^{k}+\alpha d^{k})
\]</div>
<p>线搜索的目标是选取合适的步长使得<span class="arithmatex">\(\phi(\alpha_{k})\)</span>尽可能减小，也就是</p>
<ul>
<li><span class="arithmatex">\(\alpha _k\)</span>应该使得<span class="arithmatex">\(f\)</span>充分下降</li>
<li>不应在寻找<span class="arithmatex">\(\alpha_{k}\)</span>上花费过多的计算量(由于这一点精确线搜索实际使用较少)</li>
</ul>
<p>自然的想法就是寻找<span class="arithmatex">\(\alpha_{k}\)</span>，使得<span class="arithmatex">\(\alpha_{k}=arg\min\limits_{\alpha&gt;0}\phi(\alpha)\)</span></p>
<p>那么这就是解析的最佳的步长，这种线搜索算法就称为<strong>精确线搜索算法</strong></p>
<h3 id="_10">非精确线搜索算法</h3>
<p>如果不要求<strong>最小</strong>仅要求满足某些不等式约束条件，这种线搜索方法就称为非精确线搜索算法，选取<span class="arithmatex">\(\alpha_{k}\)</span>需要满足的要求被称为<strong>线搜索准则</strong>，线搜索准则的合适与否直接决定了算法的收敛性。</p>
<ul>
<li>Armijo准则</li>
<li>Goldstein准则</li>
<li>Wolfe准则</li>
<li>Zoutendijk定理</li>
</ul>
<p>为了保证每一步的迭代充分下降引入下面的<strong>Armijo准则</strong>，这也是最基本的一个准则.</p>
<blockquote>
<p>[!tip] Armijo准则
设<span class="arithmatex">\(d^{k}\)</span>是点<span class="arithmatex">\(x^{k}\)</span>的下降方向，若</p>
<div class="arithmatex">\[f(x^{k}+\alpha d^{k})\leqslant f(x^{k})+c_{1}\alpha \nabla f(x^{k})^{T}d^{k}\]</div>
<p>则称步长<span class="arithmatex">\(\alpha\)</span>满足<strong>Armoji</strong>准则，其中<span class="arithmatex">\(c_{1}\in(0,1)\)</span>是一个常数</p>
</blockquote>
<p>为了克服Armijo准则的缺陷需要引入其他准则保证每一步的<span class="arithmatex">\(\alpha^{k}\)</span>不会太小，并且需要配合其他准则保证迭代的收敛性，因为<span class="arithmatex">\(\alpha=0\)</span>显然是满足条件的，但是此时迭代点不变</p>
<blockquote>
<p>[!example] 回退法
给定初值后，通过不断以指数方式缩小试探步长，找出第一个满足Armijo准则的点，回退法选取<span class="arithmatex">\(\alpha_{k}=\gamma^{j_{0}} \hat{\alpha}\)</span>
这种算法称为回退法是因为它的实验值由大至小，保证输出的<span class="arithmatex">\(\alpha_{k}\)</span>尽可能的大，并且由于下降方向是给定的，当<span class="arithmatex">\(\alpha\)</span>充分小时一定会满足Armijo准则，也就确保了算法一定会终止
实际应用中也会给<span class="arithmatex">\(\alpha\)</span>设定一个下界，防止步长过小</p>
</blockquote>
<p>Armoji准则只要求<span class="arithmatex">\(\left( \alpha,\phi(\alpha) \right)\)</span>必须处在某直线下方，我们也可使用相同的形式使得该点必须处在另一条直线的上方，这就是Armijo-Goldstein准则(Goldstein准则)</p>
<blockquote>
<p>[!NOTE] Goldstein准则
设<span class="arithmatex">\(d^{k}\)</span>是点<span class="arithmatex">\(x^{k}\)</span>的下降方向，若</p>
<div class="arithmatex">\[\begin{aligned}
f(x^{k}+\alpha d^{l})&amp;\leqslant f(x^{k})+c\alpha \nabla f(x^{k})^{T}d^{k}\\
f(x^{k}+\alpha d^{l})&amp;\geqslant f(x^{k})+(1-c)\alpha \nabla f(x^{k})^{T}d^{k} \end{aligned}\]</div>
<p>则称步长<span class="arithmatex">\(\alpha\)</span>满足<strong>Goldstein</strong>准则，其中<span class="arithmatex">\(c\in\left( 0, \frac{1}{2} \right)\)</span>是一个常数</p>
</blockquote>
<p>Goldstein准则也有直观的几何含义，指的是<span class="arithmatex">\(\left( \alpha,\phi(\alpha) \right)\)</span>必须在两条直线之间，这种做法就可以去掉一些过小的<span class="arithmatex">\(\alpha\)</span></p>
<p>需要指出Goldstein准则能够使得函数值充分下降但是也可能<strong>避开了最优的函数值</strong>(考虑单峰函数即可举出例子)，这引导我们给出新的Wolfe准则：</p>
<ul>
<li>第一条就是Armijo准则</li>
<li>第二个不等式是Wolfe准则的本质要求，也称为曲率条件(实际上就是<span class="arithmatex">\(\phi'(\alpha)\geqslant c_{2}\phi'(0)\)</span>)，这保证步长不会过小，因为原本的导数希望是负数(选取的是下降方向，想想下降方向的定义呢)，所以为了逼近0就可以进行放大。实际上这种做法可以改进，使得斜率必须增大的同时，也使得无法增加的特别大(可能使得步长过于宽松导致错过最优解，保证收敛的平稳性)，因此还有加强版本的Wolfe准则曲率条件：<span class="arithmatex">\(\lvert \phi'(\alpha) \rvert \leqslant c_{2}\lvert \phi'(0) \rvert)\)</span></li>
</ul>
<p>这个部分知乎有一篇<a href="https://zhuanlan.zhihu.com/p/118443321">笔记</a>我认为写的很清楚</p>
<blockquote>
<p>[!tip] Wolfe准则
设<span class="arithmatex">\(d^{k}\)</span>是点<span class="arithmatex">\(x^{k}\)</span>的下降方向，若</p>
<div class="arithmatex">\[\begin{aligned}
f(x^{k}+\alpha d^{l})&amp;\leqslant f(x^{k})+c_{1}\alpha \nabla f(x^{k})^{T}d^{k}\\
\nabla f(x^{k}+\alpha d^{l})^{T}d^{k}&amp;\geqslant c_{2}\nabla f(x^{k})^{T}d^{k} \end{aligned}\]</div>
<p>则称步长<span class="arithmatex">\(\alpha\)</span>满足<strong>Wolfe</strong>准则，其中<span class="arithmatex">\(c_{1},c_{2}\in\left( 0, 1\right)\)</span>是常数且<span class="arithmatex">\(c_{1}&lt;c_{2}\)</span></p>
</blockquote>
<p>由于极小值点满足Wolfe准则，永远满足条件2，而选择较小的<span class="arithmatex">\(c_{1}\)</span>可以使得满足条件1，那么在大多数情况下使用Wolfe准则会包含线搜索子问题的精确解</p>
<p>这里的Wolfe条件包含有强Wolfe条件和弱Wolfe条件</p>
<blockquote>
<p>[!NOTE] Zoutendijk定理
考虑一般的迭代格式：<span class="arithmatex">\(x^{k+1}=x^{k}+\alpha_{k}d^{k}\)</span>，其中<span class="arithmatex">\(d^{k}\)</span>是搜索方向，<span class="arithmatex">\(\alpha_{k}\)</span>是步长，而且满足Wolfe准则，假设目标函数下有界，连续可微并且梯度满足Lipschitz连续：<span class="arithmatex">\(\lVert \nabla f(x)-\nabla f(y) \rVert\leqslant L\lVert x-y \rVert,\forall x,y\in \mathbb{R}^{n}\)</span>
那么</p>
<div class="arithmatex">\[\sum\limits_{k=0}^{\infty} \cos ^{2}\theta_{k}\lVert \nabla f(x^{k}) \rVert ^{2}&lt;+\infty\]</div>
<p>其中<span class="arithmatex">\(\cos\theta_{k}\)</span>是负梯度<span class="arithmatex">\(-\nabla f(x^{k})\)</span>和下降方向<span class="arithmatex">\(d^{k}\)</span>夹角的余弦，即</p>
<div class="arithmatex">\[\cos\theta_{k}= \frac{-\nabla f(x^{k})^{T}d^{k}}{\lVert \nabla f(x^{k}) \rVert \lVert d^{k} \rVert }\]</div>
<p>这个不等式也被称为<strong>Zoutendijk</strong>条件</p>
</blockquote>
<p>注1：根据Zoutendijk条件即可得到成立时应当有<span class="arithmatex">\(\lim\limits_{ k\to \infty }\nabla f(x^{k})=0\)</span>，线搜索算法收敛性建立在Zoutendijk条件之上，本质要求是下降方向与负梯度方向不趋于正交，几何直观上就是如果趋于正交Tarlor展开后函数值几乎不变，所以要求<span class="arithmatex">\(d^{k}\)</span>与梯度正交方向夹角有一致下界</p>
<p>注2： 该部分主要注意Armijo准则和Zoutendijk条件即可</p>
<p>注3：对于收敛性算法和收敛性分析其实是笔者比较感兴趣的问题，希望有机会能再补充一门数值计算课(可能会选计算数学那边的课或者自己看书)，并且渐进理论也是统计上很重要的一个方向.</p>
<h2 id="_11">无约束极值问题的解法</h2>
<p>本节研究无约束极值问题</p>
<div class="arithmatex">\[
\min f(X)\ x\in E^{n}
\]</div>
<p>求解上述问题常使用<strong>迭代法</strong>，可分为两类</p>
<ul>
<li>利用函数的一阶或二阶导数，用到了函数的解析性质，称为<strong>解析法</strong></li>
<li>仅用到函数值不用到解析性质那么称为<strong>直接法</strong></li>
</ul>
<p>本章介绍几种常用的基本方法，前三种为解析法，后一种属于直接法</p>
<p>参考资料：
1. <a href="https://www.cnblogs.com/wuliytTaotao/p/10603576.html">机器学习之数学(博客园)</a>
2. <a href="https://zhuanlan.zhihu.com/p/32709034">最速下降法的简洁原理介绍</a></p>
<h3 id="_12">梯度法(最速下降法)</h3>
<h4 id="_13">梯度法的基本原理</h4>
<p>梯度下降法(Gradient descent)，顾名思义，就是自变量沿着梯度向量的反方向进行移动，因为梯度的方向是上升的方向，负梯度方向就是下降最快的方向.</p>
<p>通过在<strong>负梯度方向的一维搜索</strong>，来确定使<span class="arithmatex">\(f(X)\)</span>最小的<span class="arithmatex">\(\lambda_{k}\)</span>，这种梯度法就是所谓的<strong>最速下降法</strong>。</p>
<p>下面给出计算步骤：</p>
<h4 id="_14">计算步骤</h4>
<ol>
<li>给定初始近似点和精度要求，如果精度满足，即为近似极小点</li>
<li>若是不满足，求步长，计算下个迭代点，求步长的方法可用精确线搜索(最佳步长)，或非精确线搜索</li>
<li>一般的，如此迭代直到找到符合条件的近似解</li>
</ol>
<p>若是<span class="arithmatex">\(f(X)\)</span>具有二阶连续偏导数，那么在<span class="arithmatex">\(X^{(k)}\)</span>作泰勒展开就可以近似：</p>
<div class="arithmatex">\[
\begin{aligned}
f(X^{(k)}-\lambda \nabla f(X^{(k)}))\approx f(X^{(k)})-\nabla f(X^{(k)})^{T}\lambda \nabla f(X^{(k)})\\
+\frac{1}{2}\lambda\nabla f(X^{(k)})^{T}H(X^{(k)}) \nabla f(X^{(k)})
\end{aligned}
\]</div>
<p>那么可以对<span class="arithmatex">\(\lambda\)</span>求导使得等于0，得到近似的最佳步长</p>
<div class="arithmatex">\[
\lambda_{k}=\frac{\nabla f(X^{(k)})^{T} \nabla f(X^{(k)})}{\nabla f(X^{(k)})^{T}H(X^{(k)}) \nabla f(X^{(k)})}
\]</div>
<h4 id="_15">最速下降法算法</h4>
<p>最速下降法(Steepest descent)是梯度下降法的一种更具体实现形式，其理念为在每次迭代中选择合适的步长<span class="arithmatex">\(\alpha_{k}\)</span>，使得目标函数值能够得到最大程度的减少。</p>
<p>每一次迭代都在<strong>梯度的反方向</strong>，我们总可以找到一个新的点使得在这个方向上达到最小值，也就是方向与步长都达到最优(局部上).</p>
<p>注：每次迭代的路径与上一次垂直，并且如果梯度不等于0下一次迭代必定下降</p>
<p><img alt="最速下降法" src="https://cdn.jsdelivr.net/gh/Eurekaimer/MyIMGs@main/img/%E6%9C%80%E9%80%9F%E4%B8%8B%E9%99%8D%E6%B3%95.png" /></p>
<blockquote>
<p>[!NOTE] 最速下降法(算法)
Step 1 给出<span class="arithmatex">\(x_{1}\in \mathbb{R}^{n},0\leqslant \varepsilon \ll 1,k:=1\)</span>
Step 2 <span class="arithmatex">\(d_{k}=-\nabla f(x_{k}),\lVert d_{k} \rVert_{2}\leqslant \varepsilon\)</span>停止
Step 3 利用精确线搜索<span class="arithmatex">\(\alpha_{k}&gt;0\)</span>,<span class="arithmatex">\(f(x_{k}+\alpha_{k}d_{k})=\min\limits_{\alpha&gt;0}f(x_{k}+\alpha d_{k})\)</span>
Step 4 <span class="arithmatex">\(x_{k+1}=x_{k}+\alpha_{k} d_{k},k:=k+1\)</span>，回到2</p>
</blockquote>
<p>注：<span class="arithmatex">\(\alpha_{k}\)</span>为步长，在深度学习中被称为学习率(learning rate)，控制了梯度下降速度的快慢.</p>
<p>理解一个算法最好还是依靠例子进行实操：</p>
<blockquote>
<p>[!example] 使用梯度法
求<span class="arithmatex">\(f(X)=(x_{1}-1)^{2}+(x_{2}-1)^{2}\)</span>的极小点，<span class="arithmatex">\(\varepsilon=0.1\)</span></p>
</blockquote>
<p><code>Sol.</code></p>
<p>取初始点<span class="arithmatex">\(X^{(0)}=(0,0)^{T}\)</span></p>
<p>那么<span class="arithmatex">\(\nabla f(X)=\left[ 2(x_{1}-1),2(x_{2}-1) \right]^{T}\)</span>，<span class="arithmatex">\(\nabla f(X^{(0)})=(-2,-2)^{T}\)</span></p>
<p>还有<span class="arithmatex">\(\lVert \nabla f(X^{(0)}) \rVert^{2}=\left( \sqrt{ (-2)^{2}+(-2)^{2} } \right)^{2}=8&gt;\varepsilon\)</span></p>
<div class="arithmatex">\[
H(X)=\begin{pmatrix}
2 &amp; 0 \\
0 &amp; 2
\end{pmatrix}
\]</div>
<div class="arithmatex">\[
\begin{aligned}
\lambda_{k}&amp;=\frac{\nabla f(X^{(k)})^{T} \nabla f(X^{(k)})}{\nabla f(X^{(k)})^{T}H(X^{(k)}) \nabla f(X^{(k)})}\\
&amp;=\frac{(-2,-2)(-2,-2)^{T}}{(-2,-2)\begin{pmatrix}
2 &amp; 0 \\
0 &amp; 2 
\end{pmatrix}(-2,-2)^{T}}\\
&amp;=\frac{1}{2}
\end{aligned}
\]</div>
<div class="arithmatex">\[
X^{(1)}=X^{(0)}-\lambda_{0}\nabla f(X^{(0)})=\begin{pmatrix}
0 \\
0 
\end{pmatrix}-\frac{1}{2}\begin{pmatrix}
-2 \\
-2
\end{pmatrix}=\begin{pmatrix}
1 \\
1
\end{pmatrix}\implies \nabla f(X^{(1)})=\mathbf{0}
\]</div>
<p>求解完毕</p>
<p>需要注意的是如果确定了步长，那么不一定收敛，迭代点可能会出现来回震荡的问题，所以必须不断减少步长的值</p>
<p>注1：由于负梯度方向的最速下降性，容易被误以为负梯度方向是理想的搜索方向，但是实际上<span class="arithmatex">\(X\)</span>点处的负梯度方向在<strong>局部上才具有那种最速下降的性质，如果在全局上(对于整个极小化过程来说)则不一定</strong>.</p>
<p>注2：有时用最速下降法趋近极小点时，其搜索路径呈直角锯齿状，在开头几步，目标函数值下降较快，但接近极小点<span class="arithmatex">\(X^{*}\)</span>时，收敛速度就不理想了.特别是当目标函数的等值线椭圆比较扁平时，收敛速度就更慢了.因此，在实用中，常将梯度法和其他方法联合起来应用，在前期使用梯度法，而在接近极小点时，则使用收敛较快的其他方法.</p>
<p>注3：机器学习中的梯度下降法，梯度下降法和反向传播算法是深度学习的基石，我们用梯度下降法更新神经网络的参数，用反向传播算法一层一层地将误差由后向前传播</p>
<h3 id="conjugate-gradient-method">共轭梯度法(Conjugate gradient method)</h3>
<p>参考资料</p>
<ul>
<li><a href="https://keson96.github.io/2016/11/27/2016-11-27-Conjugate-Gradient-Method/">共轭梯度法(Conjugate Gradient Method)</a></li>
</ul>
<p>下面给出一些基本的定义：</p>
<h4 id="_16">共轭方向</h4>
<p><span class="arithmatex">\(X,Y\)</span>是<span class="arithmatex">\(\mathbb{R}^{n}\)</span>中的两个向量，若有<span class="arithmatex">\(X^{T}Y=0\)</span>，就称<span class="arithmatex">\(X,Y\)</span><strong>正交</strong></p>
<p>推广正交到<strong>共轭</strong>，再设<span class="arithmatex">\(A\)</span>为<span class="arithmatex">\(n\times n\)</span>的<strong>正定阵</strong>，那么如果<span class="arithmatex">\(X,AY\)</span><strong>正交</strong>有</p>
<div class="arithmatex">\[
X^{T}AT=0
\]</div>
<p>则称<span class="arithmatex">\(X,Y\)</span>关于<span class="arithmatex">\(A\)</span>共轭.</p>
<p>注：如果<span class="arithmatex">\(A=I\)</span>，则上述条件即为通常的<strong>正交</strong>.</p>
<p>下面是共轭的一个小的性质：</p>
<blockquote>
<p>[!NOTE] 定理(共轭独立)
<span class="arithmatex">\(A\)</span>为<span class="arithmatex">\(n\times n\)</span>正定阵，<span class="arithmatex">\(P^{1},P^{2},\dots,P^{n}\)</span>为<span class="arithmatex">\(A\)</span>共轭的非零向量，那么这组向量线性无关</p>
</blockquote>
<p><code>Proof.</code></p>
<p>按照定义写出线性表达式，然后利用共轭乘上其中任意一个向量与<span class="arithmatex">\(A\)</span>的乘积，<span class="arithmatex">\(\left( P^{i} \right)^{T}A\)</span>，根据共轭可知<span class="arithmatex">\(\alpha_{i}=0\)</span>，循环使用得线性无关.</p>
<p>考虑无约束极值问题的一个特殊情形：</p>
<div class="arithmatex">\[
\min f(X)= \frac{1}{2}X^{T}AX+B^{T}X+c
\]</div>
<p>其中A为对称正定阵，<span class="arithmatex">\(X,B\in E^{n},c\in \mathbb{R}\)</span></p>
<blockquote>
<p>上面的问题也被称为<strong>正定二次函数极小问</strong>题，在整个最优化问题中起着极其重要的作用</p>
</blockquote>
<p>对于这个问题有一个很有用的定理</p>
<blockquote>
<p>[!NOTE] 二次终止定理
设向量<span class="arithmatex">\(P_{i},i=0,\dots,n-1\)</span>为A的共轭，从任一点<span class="arithmatex">\(X^{(0)}\)</span>出发分别以<span class="arithmatex">\(P^{(0)},P^{(1)},\dots,P^{(n-1)}\)</span>为搜索方向的算法，经过n次一维搜索收敛于问题的极小点</p>
</blockquote>
<p><code>Proof.</code></p>
<p><span class="arithmatex">\(\nabla f(X)=AX+B\)</span>，设每次搜索后得到的近似解为<span class="arithmatex">\(X^{(1)},\dots,X^{(n)}\)</span>，相继代入算法方程可知：</p>
<div class="arithmatex">\[
\nabla f(X^{(n)})=\nabla f(X^{(k+1)})+\lambda_{k+1}AP^{(k+1)}+\dots\lambda_{n-1}AP^{(n-1)}
\]</div>
<p>由于一维搜索时为了确定最佳步长有<span class="arithmatex">\(\nabla f(X^{(k+1)})P^{(k)}=0\)</span></p>
<div class="arithmatex">\[
\begin{aligned}
(P^{(k)})^{T}\nabla f(X^{(n)})&amp;=(P^{(k)})^{T}\nabla f(X^{(k+1)})+\lambda_{k+1}(P^{(k)})^{T}AP^{(k+1)}+\dots\lambda_{n-1}(P^{(k)})^{T}AP^{(n-1)}\\
&amp;=0
\end{aligned}
\]</div>
<p>从而可知<span class="arithmatex">\(\nabla f(X^{(n)})=0\)</span></p>
<p>十分巧妙的利用最优步长的方程式代入化简递推式</p>
<p>注：任一初始点的条件十分强大，因为推导过程中由于共轭的性质将所有的项全部归为0了，<strong>收敛速度与初始点无关，并且一定会收敛</strong>！</p>
<h4 id="_17">正定二次函数的共轭梯度法</h4>
<p>由于<span class="arithmatex">\(A\)</span>对称正定阵，存在唯一极小点，若是已知某共轭向量组可以利用上述定理求得极小点，这就是共轭梯度法</p>
<div class="arithmatex">\[
\left\{ \begin{matrix}
X^{(k+1)}=X^{(k)}+\lambda_{k}P^{(k)} \\
\lambda_{k}:\min\limits_{\lambda} f(X^{(k)}+\lambda P^{(k)}) \\
X^{(n)}=X^{*}
\end{matrix} \right.
\]</div>
<p>下面开始详细解释共轭梯度法的过程和公式推导的过程：</p>
<p>注：一个重要的迭代条件是<span class="arithmatex">\(\nabla f(X)=AX+B\implies\)</span></p>
<div class="arithmatex">\[
\nabla f(X^{(k+1)})-\nabla f(X^{(k)})=A(X^{(k+1)}-X^{(k)})
\]</div>
<p>但是<span class="arithmatex">\(X^{(k+1)}=X^{(k)}+\lambda_{k}P^{(k)}\implies \nabla f(X^{(k+1)})-\nabla f(X^{(k)})=\lambda_{k}AP^{(k)}\)</span></p>
<ol>
<li>任取初始近似点，并以该点的负梯度方向为搜索方向也就是<span class="arithmatex">\(P^{(0)}=-\nabla f(X^{(0)})\)</span></li>
<li>进行一维搜索，沿着<span class="arithmatex">\(X^{(0)}+\lambda P^{(0)}\)</span>，算出<span class="arithmatex">\(\nabla f(X^{(1)})\)</span>，根据原本的共轭性质得到<span class="arithmatex">\(\nabla f(X^{(1)})^{T}P^{(0)}=-\nabla f(X^{(1)})^{T}\nabla f(X^{(0)})=0\)</span>，从而可知正交</li>
<li>不同迭代点的梯度构成正交系，于是可以在它们生成的二维子空间内寻找<span class="arithmatex">\(P^{(1)}=-\nabla f(X^{(1)})+\alpha_{0}\nabla f(X^{(0)})\)</span></li>
</ol>
<p>注：为了满足正交的条件也就是需要满足方程组：</p>
<div class="arithmatex">\[
\left[ -\nabla f(X^{(1)})+\alpha_{0}\nabla f(X^{(0)}) \right] ^{T}\left[  \nabla f(X^{(1)})-\nabla f(X^{(0)}) \right] =0
\]</div>
<p>方便起见令<span class="arithmatex">\(\beta_{0}=-\alpha_{0}= \frac{\nabla f(X^{(1)})^{T}\nabla f(X^{(1)})}{\nabla f(X^{(0)})^{T}\nabla f(X^{(0)})}\)</span></p>
<div class="arithmatex">\[
P^{(1)}=-\nabla f(X^{(1)})+\beta_{0}P^{(0)}
\]</div>
<ol>
<li>下面的过程类似，同样是正交系，在子空间内找下一个共轭的向量，然后继续推导迭代点的梯度</li>
</ol>
<p>一直迭代就可以得到一般的共轭梯度法计算公式：</p>
<div class="arithmatex">\[
\left\{ \begin{matrix}
X^{(k+1)}&amp;=&amp;X^{(k)}+\lambda_{k}P^{(k)} \\
\lambda_{k}&amp;=&amp;- \frac{\nabla f(X^{(k)})^{T}P^{(k)}}{(P^{(k)})^{T}AP^{(k)}} \\
P^{(k+1)}&amp;=&amp;-\nabla f(X^{(k+1)})+\beta_{k}P^{(k)} \\
\beta_{k}&amp;= &amp;\frac{\nabla f(X^{(k+1)})^{T}\nabla f(X^{(k+1)})}{\nabla f(X^{(k)})^{T}\nabla f(X^{(k)})} \\
k&amp;=&amp;0,1,2\dots,n-1
\end{matrix} \right.
\]</div>
<h4 id="_18">计算步骤</h4>
<ol>
<li>选择初始近似，给出允许误差</li>
<li>计算共轭向量，导出下一个迭代点，计算步长可以使用一维搜索法</li>
<li>继续迭代下一个近似点</li>
<li>若是梯度模平方小于允许误差就停止,否则回到3</li>
</ol>
<p>注：理论上二次函数只要迭代n次一定可以找到极小点，但是<strong>实际计算中由于数据的舍入和计算误差积累往往不能达到</strong>，但是维数最大到n继续迭代没有意义，那么就应当以<span class="arithmatex">\(X^{(n)}\)</span>作为新的初始近似，<strong>重新开始迭代</strong>.</p>
<p>理论总是比较枯燥的，下面给出一个实例：</p>
<blockquote>
<p>[!example] 试用共轭梯度法求下述二次函数的极小点
$<span class="arithmatex">\(f(X)= \frac{3}{2}x_{1}^{2}+ \frac{1}{2}x_{2}^{2}-x_{1}x_{2}-2x_{1}\)</span>$</p>
</blockquote>
<p><code>Sol.</code></p>
<p>化为<span class="arithmatex">\(f(X)= \frac{1}{2}X^{T}AX+B^{T}X+c\)</span>的形式：</p>
<div class="arithmatex">\[
A=\begin{pmatrix}
3 &amp; -1 \\
-1 &amp; 1
\end{pmatrix}
\]</div>
<p><span class="arithmatex">\(X^{(0)}=(-2,4)^{T},\nabla f(X)=\left[ (3x_{1}-x_{2}-2),(x_{2}-x_{1}) \right]^{T},\nabla f(X^{(0)})=(-12,6)^{T}\)</span></p>
<p>可以得到<span class="arithmatex">\(\lambda_{0}= - \frac{\nabla f(X^{(0)})^{T}P^{(0)}}{(P^{(0)})^{T}AP^{(0)}},P^{(0)}=-\nabla f(X^{(0)})\)</span></p>
<p>然后<span class="arithmatex">\(X^{(1)}=X^{(0)}+\lambda_{0}P^{(0)},\beta_{0}= \frac{\nabla f(X^{(1)})^{T}\nabla f(X^{(1)})}{\nabla f(X^{(0)})^{T}\nabla f(X^{(0)})}\)</span>，继续迭代即可</p>
<p>注：为了掌握这种方法，建议还是多做一些练习</p>
<h4 id="_19">非二次函数的共轭梯度法</h4>
<p>这种不规整的问题往往采用的都是化归方法，将复杂问题转化为我们研究过的比较简单的问题，也就是在迭代点附近做二阶的泰勒展开，就可以当作二次函数做了.</p>
<p>对于一般的非二次函数，共轭梯度法的计算依然适用，公式同理</p>
<p>一般非二次函数使共轭性遭受破坏，因而要以<span class="arithmatex">\(n\)</span>步迭代取得终止常常是不可能的。所以在实际应用时，如迭代步数<span class="arithmatex">\(k\leqslant n\)</span>已达到要求的精度，则以<span class="arithmatex">\(X(k)\)</span>作为要求的近似解。否则可将前n步作为一个循环，同时以所得到的<span class="arithmatex">\(X(n)\)</span>作为新的初始近似重新开始，进行第二个循环。重复进行，直至满足要求的精度为止。 </p>
<p>注1：有趣的拓展，关于共轭梯度法还有许多不同的公式，例如Fletcher-Reeves公式、Dai-Yuan公式等(四个方法)，四个方法可通过两个分子分母的组合得到，另一个重要的共轭梯度法PRP方法，在实际中表现比Fletcher-Reeves方法好得多.</p>
<p>注2：这里的拓展可以深挖，主要是不同的<span class="arithmatex">\(\beta_{k}\)</span>的问题，其中的原理可以查阅相关的参考文献</p>
<h3 id="_20">牛顿法与拟牛顿法</h3>
<blockquote>
<p>拟牛顿法是近30多年来发展起来的，它是求解无约束极值问题的一种有效方法。由于它既避免了计算二阶导数矩阵及其求逆过程，又比梯度法的收敛速度快，特别是对高维问题具有显著的优越性，因而使变尺度法获得了很高的声誉，至今仍被公认为求解无约束极值问题最有效的算法之一</p>
</blockquote>
<h4 id="_21">牛顿法原理</h4>
<p>假定无约束极值问题的目标函数二阶可求偏导，<span class="arithmatex">\(X^{(k)}\)</span>为其极小点的某一近似，在这个点附近取<span class="arithmatex">\(f(X)\)</span>的二阶泰勒展开：</p>
<div class="arithmatex">\[
f(X)\approx f(X^{(k)})+\nabla f(X^{(k)})^{T}\Delta X+\frac{1}{2} \Delta X^{T}H(X^{(k)})\Delta X
\]</div>
<p>极小点满足<span class="arithmatex">\(\nabla f(X^{(k)})+H(X^{(k)})\Delta X=0\)</span></p>
<p>从而<span class="arithmatex">\(X=X^{(k)}-H(X^{(k)})^{-1}\nabla f(X^{(k)})\)</span></p>
<p>那么如果函数是二次函数，Hesse阵就是常数阵，逼近是准确的，从任意一点出发一步即可求出<span class="arithmatex">\(f(X)\)</span>的极小点(假定<span class="arithmatex">\(H(X^{(k)})\)</span>正定)</p>
<p>如果不是，那么就是近似表达式，这时就常常取<span class="arithmatex">\(-H(X^{(k)}\nabla f(X^{(k)}))\)</span>为搜索方向，即</p>
<div class="arithmatex">\[
\left\{ \begin{matrix}
P^{(k)}=-H(X^{(k)})^{-1}\nabla f(X^{(k)}) \\
X^{(k+1)}=X^{(k)}+\lambda_{k}P^{(k) } \\
\lambda_{k}:\min f(X^{(k)}+\lambda P^{(k)})
\end{matrix} \right.
\]</div>
<p>牛顿法的算法：</p>
<ol>
<li>给出初始点<span class="arithmatex">\(x_{1}\in \mathbb{R}^{n},0\leqslant \varepsilon&lt;1,k:=1\)</span></li>
<li>如果<span class="arithmatex">\(\lVert \nabla f(x_{k}) \rVert_{2}\leqslant \varepsilon\)</span>，停止，否则<span class="arithmatex">\(d_{k}=-\left[ \nabla^{2}f(x_{k}) \right]^{-1}\nabla f(x_{k})\)</span>(Newton Step)</li>
<li>利用线搜索求<span class="arithmatex">\(\alpha_{k}&gt;0\)</span>;<span class="arithmatex">\(x_{k+1}=x_{k}+\alpha_{k}d_{k};k=k+1\)</span>，回到2</li>
</ol>
<p>如果<span class="arithmatex">\(\nabla^{2}f(x_{k})\)</span>不正定，那么牛顿法的搜索方向可能不是下降方向，就需要修正，将牛顿法的搜索方向记为<span class="arithmatex">\(d_{k}^{N}\)</span>(Newton step)</p>
<p>修正方法：</p>
<div class="arithmatex">\[
d_{k}=\left\{ \begin{matrix}
d_{k}^{N},\cos(d_{k}^{N},-g_{k})\geqslant\eta \\
-g_{k},otherwise
\end{matrix} \right.
\]</div>
<p>这样可以确保搜索方向，也就保证了算法的收敛性</p>
<p>但是现实是，实际问题中的目标函数过于复杂，求逆阵是困难的于是我们设法构造另一个矩阵<span class="arithmatex">\(\overline{H}^{(k)}\)</span>，用它来直接<strong>逼近</strong>二阶导数矩阵的逆阵<span class="arithmatex">\(H(X^{(k)})^{-1}\)</span></p>
<h4 id="_22">构造近似矩阵</h4>
<p>明确一下要求是在每一步充分利用已有信息确认下一步的搜索方向，并且每做一次迭代就要使目标函数值有所下降，并且近似矩阵应当收敛于逆阵</p>
<p>由于二次函数时，Hesse阵为常数阵，那么在其任意两点<span class="arithmatex">\(X^{(k)},X^{(k+1)}\)</span>，有梯度之差为<span class="arithmatex">\(\nabla f(X^{(k+1)})-\nabla f(X^{(k)})=A(X^{(k+1)}-X^{(k)})\)</span></p>
<p>以下条件也被称为<strong>拟牛顿条件</strong></p>
<div class="arithmatex">\[
X^{(k+1)}-X^{(k)}=\overline{H}^{(k+1)}\left[ \nabla f(X^{(k+1)})-\nabla f(X^{(k)}) \right] 
\]</div>
<p>简化记号为：</p>
<div class="arithmatex">\[
\left\{ \begin{matrix}
\Delta G^{(k)}&amp;=&amp;\nabla f(X^{(k+1)})-\nabla f(X^{(k)})\\
\Delta X^{(k)}&amp;=&amp;X^{(k+1)}-X^{(k)}\\
\end{matrix}\right.
\]</div>
<p>可以简单记为<span class="arithmatex">\(\Delta X^{(k)}=\overline{H}^{(k+1)}\Delta G^{(k)}\)</span></p>
<p>那么为了使<span class="arithmatex">\(\overline{H}^{(k+1)}\)</span>满足拟牛顿条件，要求<span class="arithmatex">\(\Delta  \overline{H}^{(k)}\Delta G^{(k)}=\Delta X^{(k)}-\overline{H}^{(k)}\Delta G^{(k)}\)</span></p>
<p>可以试图构造一个简单的形式，根据上式也可以进行猜想：</p>
<div class="arithmatex">\[
\Delta  \overline{H}^{(k)}=\Delta X^{(k)}(Q^{(k)})^{T}-\overline{H}^{(k)}\Delta G^{(k)}(W^{(k)})^{T}
\]</div>
<p>那么反代就可以得到<span class="arithmatex">\((Q^{(k)})^{T}\Delta G^{(k)}=(W^{(k)})^{T}\Delta G^{(k)}=1\)</span></p>
<p>找到对应的校正矩阵：</p>
<div class="arithmatex">\[
\Delta  \overline{H}^{(k)}=\frac{\Delta X^{(k)}(\Delta X^{(k)})^{T}}{(\Delta G^{(k)})^{T}\Delta X^{(k)}}- \frac{\overline{H}^{(k)}\Delta G^{(k)}(\Delta G^{(k)})^{T}\overline{H}^{(k)}}{(\Delta G^{(k)})^{T}\overline{H}^{(k)}\Delta G^{(k)}}
\]</div>
<p>可以利用校正矩阵得到</p>
<div class="arithmatex">\[
\overline{H}^{(k+1)}=\overline{H}^{(k)}+ \frac{\Delta X^{(k)}(\Delta X^{(k)})^{T}}{(\Delta G^{(k)})^{T}\Delta X^{(k)}}- \frac{\overline{H}^{(k)}\Delta G^{(k)}(\Delta G^{(k)})^{T}\overline{H}^{(k)}}{(\Delta G^{(k)})^{T}\overline{H}^{(k)}\Delta G^{(k)}}
\]</div>
<p>拟牛顿法的计算步骤：</p>
<ol>
<li>给定初始点<span class="arithmatex">\(X^{(0)}\)</span>及梯度允许误差<span class="arithmatex">\(\varepsilon&gt;0\)</span></li>
<li>若 $$ \lVert \nabla f(X^{(0)}) \rVert ^{2}\leqslant \varepsilon $$
则<span class="arithmatex">\(X^{(0)}\)</span>为近似极小点，停止，否则转入3</li>
<li>令<span class="arithmatex">\(\overline{H}^{(0)}=I,P^{(0)}=-\overline{H}^{(0)}\nabla f(X^{(0)})\)</span></li>
</ol>
<p>注1:上述方法首先由戴维顿(Davidon)提出，后经弗莱彻(Fletcher)和鲍威尔(Powell)加以改进，故称<strong>DFP法</strong>，或<strong>DFP拟牛顿法</strong>.</p>
<p>注2:拟牛顿法也称为变尺度(variable metric)方法.</p>
<h4 id="smwsherman-morrison-woodbury-formula">SMW(Sherman-Morrison-Woodbury) Formula</h4>
<div class="arithmatex">\[
(A+UV^{T})^{-1}=A^{-1}-A^{-1}U(I_{k}+V^{T}A^{-1}U)^{-1}V^{T}A^{-1}
\]</div>
<p>高阶矩阵和低秩矩阵如何快速求解逆阵？直接对低秩的矩阵进行求逆计算就可以节约大量的计算量!</p>
<p>注：曾经在高等代数中遇到过并且写过习题(<strong>参考谢启鸿白皮书</strong>)</p>
<p>下面是另一个著名的拟牛顿法：</p>
<h4 id="bfgs">BFGS方法</h4>
<p>它的矩阵修正公式为：</p>
<div class="arithmatex">\[
\begin{aligned}
B_{k+1}&amp;=B_{k}- \frac{B_{k}s_{k}s_{k}^{T}B_{k}}{s_{k}^{T}B_{k}s_{k}}+ \frac{y_{k}y_{k}^{T}}{s_{k}^{T}y_{k}}\\
H_{k+1}&amp;=H_{k}- \frac{H_{k}y_{k}s_{k}^{T}+s_{k}y_{k}^{T}H_{k}}{y_{k}^{T}s_{k}}+\left( 1+ \frac{y_{k}^{T}H_{k}y_{k}}{s_{k}^{T}y_{k}} \right) \frac{s_{k}s_{k}^{T}}{s_{k}^{T}y_{k}}
\end{aligned}
\]</div>
<p>注意如果将<span class="arithmatex">\(B_{k}\iff H_{k},s_{k}\iff y_{k}\)</span>对换，那么可以将DFP方法和BFGS方法相互转换(对偶性质)，BFGS和DFP方法称为互为对偶方法.</p>
<p>Broyden利用BFGS和DFP公式构造出一族拟牛顿修正公式：</p>
<div class="arithmatex">\[
B_{k+1}(\theta)=B_{k}- \frac{B_{k}s_{k}s_{k}^{T}B_{k}}{s_{k}^{T}B_{k}s_{k}}+ \frac{y_{k}y_{k}^{T}}{s_{k}^{T}y_{k}}+\theta w_{k}w_{k}^{T}
\]</div>
<p>取<span class="arithmatex">\(\theta=0\)</span>得到BFGS修正公式，<span class="arithmatex">\(\theta=1\)</span>得到DFP修正公式</p>
<p>一族包含三个参数的修正公式由Huang给出形式为：</p>
<div class="arithmatex">\[
H_{k+1}=H_{k}- \frac{H_{k}y_{k}y_{k}^{T}H_{k}}{y_{k}^{T}H_{k}y_{k}}+\rho_{k} \frac{s_{k}s_{k}^{T}}{s_{k}^{T}y_{k}}+(\tau_{k}s_{k}+\xi_{k}H_{k}y_{k}) v_{k}
\]</div>
<p>那么Broyden族是Huang族中所有对称且满足拟牛顿方程的修正公式</p>
<p>拟牛顿法有两个重要的性质：</p>
<h4 id="_23">不变性和二次终止性</h4>
<ul>
<li>不变性</li>
</ul>
<p>拟牛顿法的一个重要性质是不变性(invariance)，也就是经过线性变换后不变，利用这个性质分析算法时可以把<span class="arithmatex">\(H_{1}=1\)</span>假设代入.</p>
<p>线性变换：<span class="arithmatex">\(\overset{\sim}{x}=Ax+a\)</span>，目标函数变为<span class="arithmatex">\(f(A^{-1}(\overset{\sim}{x}-a))=f(x)\)</span></p>
<div class="arithmatex">\[
\nabla \overset{\sim}{x}\overset{\sim}{f}(\overset{\sim}{x})=A^{-T}\nabla f(x)
\]</div>
<ul>
<li>二次终止性</li>
</ul>
<p>Huang族中的任何方法在精确线搜索下具有二次终止性，在一定条件的假定下，算法必有限终止</p>
<blockquote>
<p>拟牛顿法的收敛性一直以来是比较热门的研究课题，拟牛顿法收敛性研究比较成熟和完善，但仍有一些重要问题没有解决，比如DFP方法的总体收敛性问题.</p>
</blockquote>














                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="lucide lucide-circle-arrow-up" viewBox="0 0 24 24"><circle cx="12" cy="12" r="10"/><path d="m16 12-4-4-4 4M12 16V8"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024-2026 Eurekaimer

    </div>
  
  
    Made with
    <a href="https://zensical.org/" target="_blank" rel="noopener">
      Zensical
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    
      
      
      
      <script id="__config" type="application/json">{"annotate":null,"base":"../../..","features":["announce.dismiss","content.action.edit","content.action.view","content.code.annotate","content.code.copy","content.code.select","content.footnote.tooltips","content.tabs.link","content.tooltips","header.autohide","navigation.expand","navigation.footer","navigation.indexes","navigation.instant","navigation.instant.prefetch","navigation.instant.progress","navigation.path","navigation.prune","navigation.sections","navigation.tabs","navigation.tabs.sticky","navigation.top","navigation.tracking","search.highlight","toc.follow"],"search":"../../../assets/javascripts/workers/search.e2d2d235.min.js","tags":null,"translations":{"clipboard.copied":"已复制","clipboard.copy":"复制","search.result.more.one":"在该页上还有 1 个符合条件的结果","search.result.more.other":"在该页上还有 # 个符合条件的结果","search.result.none":"没有找到符合条件的结果","search.result.one":"找到 1 个符合条件的结果","search.result.other":"# 个符合条件的结果","search.result.placeholder":"键入以开始搜索","search.result.term.missing":"缺少","select.version":"选择当前版本"},"version":null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.8ffeb9c9.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>